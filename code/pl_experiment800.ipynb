{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cvxopt\n",
    "from cvxopt import matrix, solvers, spmatrix, sparse\n",
    "import scipy\n",
    "from scipy.sparse import csr_matrix, hstack, vstack\n",
    "import pickle\n",
    "import gc\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MaxAbsScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mape_score(y_true, y_predicted):\n",
    "    return np.mean(np.abs(y_true - y_predicted) / y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(171684,)\n",
      "(9036,)\n",
      "[171684  23379]\n"
     ]
    }
   ],
   "source": [
    "y = np.load('train_test_split/y_train.npy')\n",
    "print(y.shape)\n",
    "s = np.load('train_test_split/s_train.npy')\n",
    "print(s.shape)\n",
    "loader = np.load('train_test_split/X_train.npz')\n",
    "X = csr_matrix((loader['data'], loader['indices'], loader['indptr']), shape=loader['shape'])\n",
    "shape = loader['shape']\n",
    "print(shape)\n",
    "\n",
    "D = 19\n",
    "N = X.shape[1]\n",
    "P = int(X.shape[0] / D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\r\n",
      "Mem:            62G        5.2G         31G        1.7G         26G         55G\r\n",
      "Swap:            0B          0B          0B\r\n"
     ]
    }
   ],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut = 800\n",
    "if cut != 0:\n",
    "    X = X[:D*cut, :]\n",
    "    y = y[:D*cut]\n",
    "    s = s[:cut]\n",
    "P = int(X.shape[0] / D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\r\n",
      "Mem:            62G        1.2G         35G        1.7G         26G         59G\r\n",
      "Swap:            0B          0B          0B\r\n"
     ]
    }
   ],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MaxAbsScaler(copy=False)\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09662130994752376"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.nnz / X.shape[0] / X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**======================================================================================**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "    'mse_train': {}, 'mse_test': {},\n",
    "    'mape_train': {}, 'mape_test': {},\n",
    "    'clf_train': {}, 'clf_test': {}, \n",
    "    'native3_train': {}, 'native3_test': {},\n",
    "    'lambda_opt_max': {}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_opt = cvxopt.sparse(matrix(np.load('P_opt_dense.npy')[:P*D, :P*D]))\n",
    "q_opt = -np.ones(P*D)\n",
    "q_opt = matrix(q_opt)\n",
    "eq_constraintA = cvxopt.sparse(matrix(np.diag(y)))\n",
    "eq_constraintb = matrix(np.zeros(P*D))\n",
    "G_opt = cvxopt.sparse(matrix(np.vstack([-np.eye(P*D), np.eye(P*D)])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "native_indices = np.arange(P) * D\n",
    "native_X = X[native_indices].toarray()\n",
    "native_X.shape\n",
    "X_T_X = native_X.T @ native_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\r\n",
      "Mem:            62G        9.1G         27G        1.7G         26G         51G\r\n",
      "Swap:            0B          0B          0B\r\n"
     ]
    }
   ],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15200,)\n",
      "(800,)\n",
      "(15200, 23379)\n"
     ]
    }
   ],
   "source": [
    "y_test = np.load('train_test_split/y_train.npy')[-cut * D:]\n",
    "print(y_test.shape)\n",
    "s_test = np.load('train_test_split/s_train.npy')[-cut:]\n",
    "print(s_test.shape)\n",
    "loader = np.load('train_test_split/X_train.npz')\n",
    "X_test = csr_matrix((loader['data'], loader['indices'], \n",
    "                     loader['indptr']), shape=loader['shape'])[-cut * D:, :]\n",
    "print(X_test.shape)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_opt = cvxopt.sparse(matrix(-np.eye(P*D)))\n",
    "h_opt = matrix(np.zeros(P*D))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C_r: 0.1\n",
      "max lambda: -1.3201202356226086e-22\n",
      "w norm 4.416065773562491\n",
      "C_r: 1.0\n",
      "max lambda: -8.676753937151074e-22\n",
      "w norm 5.059993036995107\n",
      "C_r: 10.0\n",
      "max lambda: -1.6570981737696922e-21\n",
      "w norm 5.179942278732299\n",
      "C_r: 100.0\n",
      "max lambda: -6.34678689594435e-21\n",
      "w norm 5.194690552908752\n",
      "CPU times: user 15.5 s, sys: 12.6 s, total: 28.1 s\n",
      "Wall time: 2min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for C_r in np.power(10.0, np.arange(-1, 3)):\n",
    "    print('C_r:', C_r)\n",
    "    C_r_str = f'{C_r}'\n",
    "    if C_r >= 1:\n",
    "        C_r_str = f'{int(C_r)}'\n",
    "    suffix = f'repeat'\n",
    "    a_inv_filename = f'A_inv_{cut}_{C_r_str}_{suffix}.npy'\n",
    "    a_inv_ckpt = Path(a_inv_filename)\n",
    "    if a_inv_ckpt.exists():\n",
    "        A_inv = np.load(a_inv_filename)\n",
    "    else:\n",
    "        eigvals, v = scipy.linalg.eigh(scipy.sparse.eye(N) + 2*C_r*X_T_X) #coeff\n",
    "        A = v @ np.diag(np.sqrt(eigvals)) @ scipy.linalg.inv(v)\n",
    "        A_inv = scipy.linalg.inv(A)\n",
    "        np.save(a_inv_filename, A_inv)\n",
    "\n",
    "    b_filename = f'B_{cut}_{C_r_str}_{suffix}.npy'\n",
    "    b_ckpt = Path(b_filename)\n",
    "    if b_ckpt.exists():\n",
    "        B = np.load(b_filename)\n",
    "    else:\n",
    "        B = C_r * (A_inv @ native_X.T) @ s\n",
    "        np.save(b_filename, B)\n",
    "\n",
    "    q_opt = (X @ B) * y - 1\n",
    "    q_opt = matrix(q_opt)\n",
    "\n",
    "    sol_filename = f'sol_{cut}_{C_r_str}_{suffix}.dump'\n",
    "    sol_ckpt = Path(sol_filename)\n",
    "    if sol_ckpt.exists():\n",
    "        with open(sol_filename, 'rb') as f:\n",
    "            sol = pickle.load(f)\n",
    "    else:\n",
    "        sol = solvers.qp(P_opt, q_opt, G_opt, h_opt, eq_constraintA, eq_constraintb,\n",
    "                         options={'max_iters':50})\n",
    "        with open(sol_filename, 'wb') as f:\n",
    "            pickle.dump(sol, f)\n",
    "\n",
    "    lambda_opt = np.array(sol['x'])[:, 0]\n",
    "    print('max lambda:', (lambda_opt * y).sum())\n",
    "    results['lambda_opt_max'][C_r_str] = lambda_opt.max()\n",
    "\n",
    "    w_filename = f'w_{cut}_{C_r_str}_{suffix}.npy'\n",
    "    w_ckpt = Path(w_filename)\n",
    "    if w_ckpt.exists():\n",
    "        w = np.load(w_filename)\n",
    "    else:\n",
    "        w_transformed = A_inv @ X.T @ (lambda_opt * y)\n",
    "        w = A_inv @ (w_transformed + B)\n",
    "        np.save(w_filename, w)\n",
    "    print('w norm', np.linalg.norm(w))\n",
    "\n",
    "    predicted_affinities = (X_test @ w).reshape(s_test.shape[0], D)\n",
    "    predicted_affinities_train = (X @ w).reshape(s.shape[0], D)\n",
    "\n",
    "    results['mse_test'][C_r_str] = mean_squared_error(s_test, predicted_affinities[:, 0])\n",
    "    results['mape_test'][C_r_str] = mape_score(s_test, predicted_affinities[:, 0])\n",
    "    results['mse_train'][C_r_str] = mean_squared_error(s, predicted_affinities_train[:, 0])\n",
    "    results['mape_train'][C_r_str] = mape_score(s, predicted_affinities_train[:, 0])\n",
    "\n",
    "    for i in range(1, D):\n",
    "        predicted_affinities[:, i] = (predicted_affinities[:, i] > predicted_affinities[:, 0])\n",
    "        predicted_affinities_train[:, i] = (predicted_affinities_train[:, i] \n",
    "                                            > predicted_affinities_train[:, 0])\n",
    "    results['clf_test'][C_r_str] = sum(predicted_affinities.sum(1) >= D - 1) / s_test.shape[0]\n",
    "    results['native3_test'][C_r_str] = sum(predicted_affinities.sum(1) >= D - 3) / s_test.shape[0]\n",
    "    results['clf_train'][C_r_str] = sum(predicted_affinities_train.sum(1) >= D - 1) / s.shape[0]\n",
    "    results['native3_train'][C_r_str] = sum(predicted_affinities_train.sum(1) >= D - 3) / s.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "for C in [1, 100, 10000]:\n",
    "    h_opt = matrix(np.hstack([np.zeros(P*D), C*np.ones(P*D)]))\n",
    "    for C_r in np.power(10.0, np.arange(-1, 2)):\n",
    "        print('C': C, 'C_r:', C_r)\n",
    "        C_r_str = f'{C_r}'\n",
    "        if C_r >= 1:\n",
    "            C_r_str = f'{int(C_r)}'\n",
    "        suffix = f'C{C}'\n",
    "        a_inv_filename = f'A_inv_{cut}_{C_r_str}_{suffix}.npy'\n",
    "        a_inv_ckpt = Path(a_inv_filename)\n",
    "        if a_inv_ckpt.exists():\n",
    "            A_inv = np.load(a_inv_filename)\n",
    "        else:\n",
    "            eigvals, v = scipy.linalg.eigh(scipy.sparse.eye(N) + 2*C_r*X_T_X) #coeff\n",
    "            A = v @ np.diag(np.sqrt(eigvals)) @ scipy.linalg.inv(v)\n",
    "            A_inv = scipy.linalg.inv(A)\n",
    "            np.save(a_inv_filename, A_inv)\n",
    "\n",
    "        b_filename = f'B_{cut}_{C_r_str}_{suffix}.npy'\n",
    "        b_ckpt = Path(b_filename)\n",
    "        if b_ckpt.exists():\n",
    "            B = np.load(b_filename)\n",
    "        else:\n",
    "            B = C_r * (A_inv @ native_X.T) @ s\n",
    "            np.save(b_filename, B)\n",
    "\n",
    "        q_opt = (X @ B) * y - 1\n",
    "        q_opt = matrix(q_opt)\n",
    "\n",
    "        sol_filename = f'sol_{cut}_{C_r_str}_{suffix}.dump'\n",
    "        sol_ckpt = Path(sol_filename)\n",
    "        if sol_ckpt.exists():\n",
    "            with open(sol_filename, 'rb') as f:\n",
    "                sol = pickle.load(f)\n",
    "        else:\n",
    "            sol = solvers.qp(P_opt, q_opt, G_opt, h_opt, eq_constraintA, eq_constraintb, \n",
    "                       kktsolver='ldl', options={'kktreg':1e-9, 'abstol':1e-4, 'max_iters':50})\n",
    "            with open(sol_filename, 'wb') as f:\n",
    "                pickle.dump(sol, f)\n",
    "\n",
    "        lambda_opt = np.array(sol['x'])[:, 0]\n",
    "        print((lambda_opt * y).sum())\n",
    "        results['lambda_opt_max'][C_r_str] = lambda_opt.max()\n",
    "\n",
    "        w_filename = f'w_{cut}_{C_r_str}_{suffix}.npy'\n",
    "        w_ckpt = Path(w_filename)\n",
    "        if w_ckpt.exists():\n",
    "            w = np.load(w_filename)\n",
    "        else:\n",
    "            w_transformed = A_inv @ X.T @ (lambda_opt * y)\n",
    "            w = A_inv @ (w_transformed + B)\n",
    "            np.save(w_filename, w)\n",
    "\n",
    "#         predicted_affinities = (X_test @ w).reshape(s_test.shape[0], D)\n",
    "#         predicted_affinities_train = (X @ w).reshape(s.shape[0], D)\n",
    "\n",
    "#         results['mse_test'][C_r_str] = mean_squared_error(s_test, predicted_affinities[:, 0])\n",
    "#         results['mape_test'][C_r_str] = mape_score(s_test, predicted_affinities[:, 0])\n",
    "#         results['mse_train'][C_r_str] = mean_squared_error(s, predicted_affinities_train[:, 0])\n",
    "#         results['mape_train'][C_r_str] = mape_score(s, predicted_affinities_train[:, 0])\n",
    "\n",
    "#         for i in range(D):\n",
    "#             predicted_affinities[:, i] = (predicted_affinities[:, i] > predicted_affinities[:, 0])\n",
    "#             predicted_affinities_train[:, i] = (predicted_affinities_train[:, i] \n",
    "#                                                 > predicted_affinities_train[:, 0])\n",
    "#         results['clf_test'][C_r_str] = sum(predicted_affinities.sum(1) >= D - 1) / s_test.shape[0]\n",
    "#         results['native3_test'][C_r_str] = sum(predicted_affinities.sum(1) >= D - 3) / s_test.shape[0]\n",
    "#         results['clf_train'][C_r_str] = sum(predicted_affinities_train.sum(1) >= D - 1) / s.shape[0]\n",
    "#         results['native3_train'][C_r_str] = sum(predicted_affinities_train.sum(1) >= D - 3) / s.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  7.4983e-10 -1.9000e+08  4e+08  1e-04  2e-10\n",
      " 1:  7.4981e-12 -1.9000e+06  4e+06  1e-06  3e-12\n",
      " 2:  7.4981e-14 -1.9000e+04  4e+04  1e-08  2e-12\n",
      " 3:  7.4981e-16 -1.9000e+02  4e+02  1e-10  2e-12\n",
      " 4:  7.4981e-18 -1.9000e+00  4e+00  1e-12  2e-12\n",
      " 5:  7.4981e-20 -1.9000e-02  4e-02  1e-14  2e-12\n",
      " 6:  7.4981e-22 -1.9000e-04  4e-04  2e-16  2e-12\n",
      " 7:  7.4981e-24 -1.9000e-06  4e-06  2e-16  2e-12\n",
      " 8:  7.4981e-26 -1.9000e-08  4e-08  2e-16  2e-12\n",
      " 9:  7.4981e-28 -1.9000e-10  4e-10  2e-16  2e-12\n",
      "10:  7.4981e-30 -1.9000e-12  4e-12  1e-16  2e-12\n",
      "Optimal solution found.\n",
      "1.882005026387209e-29\n"
     ]
    }
   ],
   "source": [
    "for C in np.power(10.0, np.arange(4, 5)):\n",
    "    h_opt = matrix(np.hstack([np.zeros(P*D), C*np.ones(P*D)]))\n",
    "    sol = solvers.qp(P_opt, q_opt, G_opt, h_opt,\n",
    "                     eq_constraintA, eq_constraintb,\n",
    "                     options={'abstol':1e-4, 'max_iters':50}) \n",
    "    C_r_str = f'{C}'\n",
    "    lambda_opt = np.array(sol['x'])[:, 0]\n",
    "    results['lambda_opt_max'][C_r_str] = lambda_opt.max()\n",
    "    print((lambda_opt * y).sum())\n",
    "    w = X.T @ (lambda_opt * y)\n",
    "\n",
    "    predicted_affinities = (X_test @ w).reshape(s_test.shape[0], D)\n",
    "    predicted_affinities_train = (X @ w).reshape(s.shape[0], D)\n",
    "\n",
    "    results['mse_test'][C_r_str] = mean_squared_error(s_test, predicted_affinities[:, 0])\n",
    "    results['mape_test'][C_r_str] = mape_score(s_test, predicted_affinities[:, 0])\n",
    "    results['mse_train'][C_r_str] = mean_squared_error(s, predicted_affinities_train[:, 0])\n",
    "    results['mape_train'][C_r_str] = mape_score(s, predicted_affinities_train[:, 0])\n",
    "\n",
    "    for i in range(D):\n",
    "        predicted_affinities[:, i] = (predicted_affinities[:, i] > predicted_affinities[:, 0])\n",
    "        predicted_affinities_train[:, i] = (predicted_affinities_train[:, i] \n",
    "                                            > predicted_affinities_train[:, 0])\n",
    "    results['clf_test'][C_r_str] = sum(predicted_affinities.sum(1) >= D - 1) / s_test.shape[0]\n",
    "    results['native3_test'][C_r_str] = sum(predicted_affinities.sum(1) >= D - 3) / s_test.shape[0]\n",
    "    results['clf_train'][C_r_str] = sum(predicted_affinities_train.sum(1) >= D - 1) / s.shape[0]\n",
    "    results['native3_train'][C_r_str] = sum(predicted_affinities_train.sum(1) >= D - 3) / s.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**========================================================================================**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
